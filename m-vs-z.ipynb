{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e53341eb",
   "metadata": {},
   "source": [
    "## **The Angular Correlation Function**\n",
    "\n",
    "The angular correlation function is a statistical tool used in cosmology to quantify the clustering of galaxies in the universe. It measures the probability of finding a galaxy at a certain angular separation from another galaxy, compared to a random distribution.\n",
    "\n",
    "**How it Works:**\n",
    "\n",
    "1. **Galaxy Catalog:** Astronomers create a catalog of galaxies, recording their positions on the celestial sphere.\n",
    "2. **Pair Counting:** They then calculate the number of galaxy pairs separated by a specific angular distance.\n",
    "3. **Comparison to Random:** This number is compared to the expected number of pairs in a random distribution of galaxies.\n",
    "4. **Correlation Function:** The angular correlation function, often denoted as w(θ), quantifies the excess or deficit of galaxy pairs at different angular separations.\n",
    "\n",
    "**What it Tells Us:**\n",
    "\n",
    "* **Large-Scale Structure:** A high value of w(θ) at large angular separations indicates that galaxies are clustered together on large scales.\n",
    "* **Small-Scale Structure:** A high value of w(θ) at small angular separations suggests that galaxies form groups and clusters.\n",
    "* **Cosmological Parameters:** By studying the angular correlation function at various scales, cosmologists can constrain cosmological parameters like the matter density and dark energy density of the universe.\n",
    "\n",
    "**Visualizing the Angular Correlation Function:**\n",
    "\n",
    "[Image of angular correlation function plot]\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* **Understanding Cosmic Structure Formation:** The angular correlation function provides insights into the processes that led to the formation of galaxies and large-scale structures.\n",
    "* **Testing Cosmological Models:** By comparing the observed angular correlation function with predictions from different cosmological models, scientists can test the validity of these models.\n",
    "* **Dark Matter and Dark Energy:** The angular correlation function can help constrain the properties of dark matter and dark energy, which make up most of the universe's mass and energy.\n",
    "\n",
    "In summary, the angular correlation function is a powerful tool for understanding the large-scale structure of the universe and the underlying physics that governs its evolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60549e29",
   "metadata": {},
   "source": [
    "## **r0: A Measure of Clustering Strength**\n",
    "\n",
    "In the context of galaxy clustering, r0 is a parameter that quantifies the strength of clustering among galaxies. It represents the characteristic scale over which galaxy clustering occurs.\n",
    "\n",
    "**How r0 Changes with Redshift and Stellar Mass:**\n",
    "\n",
    "1. **Redshift Dependence:**\n",
    "\n",
    "   * **Higher Redshift:** At higher redshifts (earlier cosmic times), galaxies tend to be more clustered. This is because the universe was denser in the past, leading to stronger gravitational forces that pulled galaxies together. As a result, the value of r0 is typically higher at higher redshifts.\n",
    "   * **Lower Redshift:** As the universe expands and becomes less dense, the clustering strength decreases. This translates to a smaller value of r0 at lower redshifts.\n",
    "\n",
    "2. **Stellar Mass Dependence:**\n",
    "\n",
    "   * **Massive Galaxies:** More massive galaxies tend to be more strongly clustered than less massive galaxies. This is because they have deeper gravitational potentials, which attract and retain more matter. As a result, massive galaxies are more likely to reside in dense environments like galaxy clusters. Consequently, the value of r0 is generally higher for massive galaxies.\n",
    "   * **Less Massive Galaxies:** Less massive galaxies, on the other hand, are less clustered and tend to be found in less dense environments. This leads to a smaller value of r0 for less massive galaxies.\n",
    "\n",
    "**Understanding the Implications:**\n",
    "\n",
    "By studying how r0 varies with redshift and stellar mass, astronomers can gain insights into the formation and evolution of galaxies and the large-scale structure of the universe. For example, a higher value of r0 at a particular redshift and stellar mass range suggests that galaxies in that epoch were more efficient at forming and growing. \n",
    "\n",
    "Furthermore, the evolution of r0 with redshift can provide clues about the nature of dark matter and dark energy, which are believed to play a crucial role in shaping the cosmic structure.\n",
    "\n",
    "\n",
    "**Visualizing the Characteristic Scale:**\n",
    "\n",
    "Imagine a cosmic web, where galaxies are interconnected like nodes in a network. The characteristic scale would represent the average distance between these nodes. In regions with strong clustering, the nodes are closer together, leading to a larger r0. In regions with weaker clustering, the nodes are more spread out, resulting in a smaller r0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.table import Table,join\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import treecorr\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "\n",
    "\n",
    "# Get the current user's home directory\n",
    "home_dir = os.path.expanduser('~')\n",
    "\n",
    "# Construct the path to the \"Thesis\" directory on the desktop\n",
    "thesis_path = os.path.join(home_dir, 'Desktop', 'Thesis')\n",
    "\n",
    "\n",
    "# Assuming you have the path to the FITS file stored in thesis_path\n",
    "fits_file_path = os.path.join(thesis_path, \"Y3_deep_fields_DB_wKNN_cat_SN-C3_zm.fits\")  # Replace with your actual file name\n",
    "t= Table.read(fits_file_path)\n",
    "masked = os.path.join(thesis_path, \"SN-C3_masked_cat.fits\")  # Replace with your actual file name\n",
    "\n",
    "t3= Table.read(masked)\n",
    "\n",
    "\n",
    "t=join(t,t3,keys='id')\n",
    "\n",
    "\n",
    "t.rename_column('ra_1','ra')\n",
    "t.rename_column('dec_1','dec')\n",
    "\n",
    "\n",
    "fits_random = os.path.join(thesis_path, \"SN-C3_randoms_ugriz_trim_video.fits\") \n",
    "\n",
    "# Open the FITS file using astropy.io.fits\n",
    "hdulist = fits.open(fits_random)\n",
    "hdulist.info()\n",
    "\n",
    "t2= Table.read(fits_random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf171c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Define the subsample regions\n",
    "subsamples = []\n",
    "\n",
    "z_mean_range=[]\n",
    "\n",
    "#z_values = [ 1.0,1.1,1.2,1.3,1.4,1.5,1.6 ]\n",
    "\n",
    "\n",
    "#!!!!problem with 0.0,0.1,0.2 samples bc it is 0\n",
    "\n",
    "\n",
    "z_values = [ 0.5,0.6,0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for i in range(len(z_values) - 1):\n",
    "\n",
    "    z_min = z_values[i]\n",
    "    z_max = z_values[i + 1]\n",
    "    z_mean= (z_min+z_max)/2\n",
    "    print(\"z_mean:\", z_mean)\n",
    "    \n",
    "    z_mean_range.append(z_mean)\n",
    "    M_max=11\n",
    "    M_min=10.5\n",
    "    \n",
    "\n",
    "    # Example subsample condition with a specific stellar mass range\n",
    "    subsample = (t['z'] > z_min) & (t['z'] <= z_max) & (t['SM'] > M_min) & (t['SM'] <= M_max)\n",
    "\n",
    "    subsamples.append(subsample)\n",
    "\n",
    "# Plot the distributions\n",
    "plt.scatter(t['z'], t['SM'], label='All galaxies')\n",
    "\n",
    "for i, subsample in enumerate(subsamples):\n",
    "    z_subsample = t['z'][subsample]\n",
    "    SM_subsample = t['SM'][subsample]\n",
    "\n",
    "\n",
    "    plt.scatter(z_subsample, SM_subsample, label=f'Subsample {i+1}')\n",
    "\n",
    "# Add dot-dashed lines for subsample regions\n",
    "for i in range(len(z_values) - 1):\n",
    "    z_min = z_values[i]\n",
    "    z_max = z_values[i + 1]\n",
    "    plt.axvline(z_min, linestyle='--', color='gray', label=f'Subsample {i+1} boundaries')\n",
    "    plt.axvline(z_max, linestyle='--', color='gray')\n",
    "\n",
    "plt.xlabel('Redshift (z)')\n",
    "plt.ylabel('Stellar Mass (SM)')\n",
    "plt.title('Galaxy Mass Distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(0,1, 0.1):\n",
    "    #z_min = i * 0.1\n",
    "    #z_max = (i + 1) * 0.1\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subsample regions\n",
    "subsamples = []\n",
    "z_mean_range=[]\n",
    "SM_mean_range=[]\n",
    "\n",
    "\n",
    "#z_values = [ 0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7, 0.8, 0.9, 1.0]\n",
    "#z_values = [ 0.5,0.6, 0.7, 0.8, 0.9, 1.0,1.1,1.2,1.3,1.4,1.5]\n",
    "\n",
    "z_values = [ 0.4,0.6,0.8,1.0,1.2,1.4]\n",
    "\n",
    "\n",
    "\n",
    "SM_range = np.linspace(9, 11, num=4)  # Create .. evenly spaced values from 8 to 11\n",
    "\n",
    "for i in range(len(z_values) - 1):\n",
    "\n",
    "    z_min = z_values[i]\n",
    "    z_max = z_values[i + 1]\n",
    "    z_mean= (z_min+z_max)/2\n",
    "    print(\"z_mean:\", z_mean)\n",
    "    \n",
    "    z_mean_range.append(z_mean)\n",
    "    \n",
    "    for j in range(len(SM_range) - 1):\n",
    "        SM_min = SM_range[j]\n",
    "        SM_max = SM_range[j+1]\n",
    "        SM_mean= (SM_min+SM_max)/2\n",
    "        print('SM_mean:', SM_mean)\n",
    "        SM_mean_range.append(SM_mean)\n",
    "\n",
    "        subsample = (t['z'] > z_min) & (t['z'] <= z_max) & (t['SM'] > SM_min) & (t['SM'] <= SM_max)\n",
    "        subsamples.append(subsample)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(t['z'], t['SM'], label='All galaxies')\n",
    "\n",
    "for i, subsample in enumerate(subsamples):\n",
    "    z_subsample = t['z'][subsample]\n",
    "    SM_subsample = t['SM'][subsample]\n",
    "\n",
    "\n",
    "    plt.scatter(z_subsample, SM_subsample, label=f'Subsample {i+1}')\n",
    "    \n",
    "    \n",
    "# Add dot-dashed lines for subsample regions\n",
    "for i in range(len(z_values) - 1):\n",
    "    z_min = z_values[i]\n",
    "    z_max = z_values[i + 1]\n",
    "    plt.axvline(z_min, linestyle='--', color='gray', label=f'Subsample {i+1} boundaries')\n",
    "    plt.axvline(z_max, linestyle='--', color='gray')\n",
    "\n",
    "\n",
    "plt.xlabel('Redshift (z)')\n",
    "plt.ylabel('Stellar Mass (SM)')\n",
    "plt.title('Galaxy Mass Distribution')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "print(\"len(subsamples)\",len(subsamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogs = []\n",
    "for i, subsamples in enumerate(subsamples):\n",
    "    ra_subset = t['ra'][subsamples]\n",
    "    dec_subset = t['dec'][subsamples]\n",
    "\n",
    "    catalog = SkyCoord(ra=ra_subset * u.deg, dec=dec_subset * u.deg)\n",
    "    catalogs.append(catalog)\n",
    "\n",
    "\n",
    "    N = len(catalog)\n",
    "    print(f\"Subsample {i+1}: N = {N}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e0229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_pairs_in_theta_bin(cat,theta_edges):\n",
    "    \"\"\"Counts the number of pairs of objects in a catalog that have an angular separation\n",
    "    within a specified theta bin.\n",
    "\n",
    "    Args:\n",
    "        catalog: An astropy.coordinates.SkyCoord object containing object coordinates.\n",
    "        theta_bins: A tuple defining the angular separation bin.\n",
    "\n",
    "    Returns:\n",
    "        The number of pairs within the theta bin.\n",
    "    \"\"\"\n",
    "    separation = cat.separation(cat[:, np.newaxis]) #Calculates the angular separation between all pairs of objects in a catalog.\n",
    "    theta_hist,_= np.histogram(np.log10(separation.value),bins=theta_edges)\n",
    "\n",
    "\n",
    "\n",
    "    return theta_hist\n",
    "\n",
    "\n",
    "\n",
    "theta_edges=np.linspace(-2.5,0.25,50) #-2.5 and 0.25 are log of the max and min separation in degrees\n",
    "theta_cen= (theta_edges[:-1]+theta_edges[1:])/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71973a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count galaxy pairs for each catalog\n",
    "pair_counts = []\n",
    "for catalog in catalogs:\n",
    "    theta_edges = np.linspace(-2.5, 0.25, 50)  # Adjust theta_edges as needed\n",
    "    dd_counts = count_pairs_in_theta_bin(catalog, theta_edges)\n",
    "    pair_counts.append(dd_counts)\n",
    "\n",
    "# Print or analyze the pair counts for each subsample\n",
    "for i, counts in enumerate(pair_counts):\n",
    "    print(f\"Subsample {i+1}:\")\n",
    "    print(counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef120b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_2 = t2['ra'][::1000]\n",
    "dec_2 = t2['dec'][::1000]\n",
    "random_catalog=SkyCoord(ra=ra_2*u.deg, dec=dec_2*u.deg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_2pcf(catalog, random_catalog, theta_edges):\n",
    "\n",
    "\n",
    "    # Calculate DD counts\n",
    "    dd_counts = count_pairs_in_theta_bin(catalog, theta_edges)\n",
    "\n",
    "    # Calculate RR counts\n",
    "    rr_counts = count_pairs_in_theta_bin(random_catalog, theta_edges)\n",
    "    \n",
    "    \n",
    "    #Normalise\n",
    "    norma_dd= dd_counts/np.sum(dd_counts) \n",
    "    norma_rr= rr_counts/np.sum(rr_counts) \n",
    "\n",
    "\n",
    "    # Calculate 2PCF\n",
    "    two_pcf = (norma_dd / norma_rr) - 1 # w_measured\n",
    "\n",
    "    return two_pcf\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd4369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate 2PCF for each catalog\n",
    "two_pcf_results = []\n",
    "for catalog in catalogs:\n",
    "    theta_edges = np.linspace(-2.5, 0.25, 50)  # Adjust theta_edges as needed\n",
    "    two_pcf = calculate_2pcf(catalog, random_catalog, theta_edges)\n",
    "    two_pcf_results.append(two_pcf)\n",
    "\n",
    "    \n",
    "# Print or analyze the 2PCF results for each subsample\n",
    "#for i, two_pcf in enumerate(two_pcf_results):\n",
    "    #print(f\"Subsample {i+1}:\")\n",
    "    #print(two_pcf)\n",
    "    #print(z_mean_range[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b7d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deg_theta_cen=10**theta_cen\n",
    "\n",
    "\n",
    "# Plot 2PCF for each catalog\n",
    "for i, two_pcf in enumerate(two_pcf_results):\n",
    "    plt.figure(figsize=(8, 6))  \n",
    "    plt.scatter(deg_theta_cen, two_pcf, label=f\"Subsample {i+1}\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(r' $ \\theta$ (degrees)')\n",
    "    plt.ylabel(r' $w(\\theta)$')\n",
    "    plt.title(f\"2PCF - Subsample {i+1}\")\n",
    "\n",
    "    # Show the plot (optional, consider saving plots)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbcdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def power_law(x, r0, gamma):\n",
    "    \"\"\"Defines the Peebles & Groth (1975) power law function.\"\"\"\n",
    "    return (x * r0) ** gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc6f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def fit_and_plot_power_law(deg_theta_cen, two_pcf_result, catalog_id):\n",
    "    \"\"\"\n",
    "    Fits a power law to the provided 2PCF data and plots the results.\n",
    "\n",
    "    Args:\n",
    "        deg_theta_cen (np.ndarray): Angular separation bins in degrees (log-scaled).\n",
    "        two_pcf_result (np.ndarray): 2PCF values for the current catalog.\n",
    "        catalog_id (int): Identifier for the current catalog (used for labeling).\n",
    "    \"\"\"\n",
    "\n",
    "    # Fit the power law using curve_fit with initial guesses\n",
    "    popt, pcov = curve_fit(power_law, deg_theta_cen[1:], two_pcf_result[1:], p0=[2e-2, -0.8])\n",
    "\n",
    "    # Extract fitted parameters\n",
    "    r0_fit = popt[0]\n",
    "    gamma_fit = popt[1]\n",
    "\n",
    "    # Calculate amplitude at 1 degree\n",
    "    amplitude_at_1deg = power_law(1, r0_fit, gamma_fit)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Print fit parameters\n",
    "    print(f\"-- Subsample {catalog_id} Power-law Fit Parameters --\")\n",
    "    print(f\"  amplitude_at_1deg:\", amplitude_at_1deg)\n",
    "    print(f\"  gamma:\", gamma_fit)\n",
    "\n",
    "    # Create the plot with appropriate axis scales and labels\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
    "    plt.scatter(deg_theta_cen, two_pcf_result, label=f\"Subsample {catalog_id}\")\n",
    "    plt.plot(deg_theta_cen, power_law(deg_theta_cen, *popt), label='Power Law Fit')\n",
    "    plt.xlabel(r' $ \\theta$ (degrees)')\n",
    "    plt.ylabel(r' $w(\\theta)$')\n",
    "    plt.title(f\"Power Law Fit for Subsample {catalog_id}\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return amplitude_at_1deg\n",
    "\n",
    "\n",
    "# Assuming 'catalogs' and 'two_pcf_results' are defined elsewhere\n",
    "for i, (catalog, two_pcf) in enumerate(zip(catalogs, two_pcf_results)):\n",
    "    deg_theta_cen=10**theta_cen\n",
    "    fit_and_plot_power_law(deg_theta_cen, two_pcf, i + 1)\n",
    "\n",
    "\n",
    "# Close all open figures (optional)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba736eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_theta_cen=10**theta_cen\n",
    "A=2*1e-2  #amplitude, best is 2*1e-2 aka 0.02\n",
    "w_fit= A*deg_theta_cen**(-0.8) #w(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54467b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate 2PCF for each catalog, including integral constraint correction\n",
    "two_pcf_results = []\n",
    "errorbars= []\n",
    "\n",
    "for catalog in catalogs:\n",
    "    dd_counts = count_pairs_in_theta_bin(catalog, theta_edges)\n",
    "    rr_counts = count_pairs_in_theta_bin(random_catalog, theta_edges)\n",
    "\n",
    "    norma_dd = dd_counts / np.sum(dd_counts)\n",
    "    norma_rr = rr_counts / np.sum(rr_counts)\n",
    "\n",
    "    two_pcf = (norma_dd / norma_rr) - 1\n",
    "\n",
    "    # Calculate integral constraint correction\n",
    "    w_IC = np.sum(w_fit * rr_counts / np.sum(rr_counts))\n",
    "\n",
    "    # Corrected 2PCF\n",
    "\n",
    "    w= two_pcf + np.sum(w_IC) # w_measured + w_IC \n",
    "        \n",
    "    fractional_error = 1 / np.sqrt(dd_counts)\n",
    "    error = fractional_error * (norma_dd / norma_rr)  #So the errorbar on the ratio DD/RR is: ( 1 / sqrt(number of  DD pairs) ) * DD/RR\n",
    "\n",
    "    errorbars.append(error)\n",
    "\n",
    "\n",
    "    two_pcf_results.append(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Save the results to a pickle file\n",
    "with open('two_pcf_results.pkl', 'wb') as f:\n",
    "    pickle.dump(two_pcf_results, f)\n",
    "\n",
    "with open('errorbars.pkl', 'wb') as f:\n",
    "    pickle.dump(errorbars, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the pickle file\n",
    "with open('two_pcf_results.pkl', 'rb') as f:\n",
    "    loaded_two_pcf_results = pickle.load(f)\n",
    "\n",
    "with open('errorbars.pkl', 'rb') as f:\n",
    "    loaded_errorbars = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0863bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot 2PCF for each catalog\n",
    "for i, w in enumerate(two_pcf_results):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(deg_theta_cen, w, label=f\"Subsample {i+1}\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    #plt.plot(deg_theta_cen, power_law(deg_theta_cen, *popt), label='Power Law Fit')\n",
    "    \n",
    "    plt.plot(deg_theta_cen, w_fit, label='Power Law Fit')\n",
    " \n",
    "    plt.xlabel(r' $ \\theta$ (degrees)')\n",
    "    plt.ylabel(r' $w(\\theta)$')\n",
    "    plt.title(f\"2PCF - Subsample {i+1}\")\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4fafb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_and_plot_power_law(deg_theta_cen, two_pcf_result, catalog_id,  max_nfev=2000):\n",
    "    \n",
    "    popt, pcov = curve_fit(power_law, deg_theta_cen[1:], two_pcf_result[1:], \n",
    "                         p0=[2e-2, -0.8], maxfev=max_nfev)\n",
    "\n",
    "    # Extract fitted parameters\n",
    "    r0_fit = popt[0]\n",
    "    gamma_fit = popt[1]\n",
    "\n",
    "    # Calculate amplitude at 1 degree\n",
    "    amplitude_at_1deg = power_law(1, r0_fit, gamma_fit)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Print fit parameters\n",
    "    print(f\"-- Subsample {catalog_id} Power-law Fit Parameters --\")\n",
    "    print(f\"  amplitude_at_1deg:\", amplitude_at_1deg)\n",
    "    print(f\"  gamma:\", gamma_fit)\n",
    "\n",
    "    # Create the plot with appropriate axis scales and labels\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
    "    plt.scatter(deg_theta_cen, two_pcf_result, label=f\"Subsample {catalog_id}\")\n",
    "    plt.plot(deg_theta_cen, power_law(deg_theta_cen, *popt), label='Power Law Fit')\n",
    "    plt.xlabel(r' $ \\theta$ (degrees)')\n",
    "    plt.ylabel(r' $w(\\theta)$')\n",
    "    plt.title(f\"Power Law Fit for Subsample {catalog_id}\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return amplitude_at_1deg\n",
    "\n",
    "amplitudes = []\n",
    "for i, w in enumerate(two_pcf_results):\n",
    "    amplitude = fit_and_plot_power_law(deg_theta_cen, w, i + 1, max_nfev=4000)\n",
    "    amplitudes.append(amplitude)\n",
    "\n",
    "print(\"Amplitudes for each subsample:\", amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c377b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amplitudes = []\n",
    "\n",
    "#for i, (catalog, two_pcf) in enumerate(zip(catalogs, two_pcf_results)):\n",
    "for i, w in enumerate(two_pcf_results):\n",
    "\n",
    "    amplitude= power_law(1, 2e-2, -0.8)\n",
    "\n",
    "    amplitudes.append(amplitude)\n",
    "\n",
    "print(\"Amplitudes for each subsample:\", amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c89903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import Planck15\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font',**{'family':'serif','size':18})\n",
    "plt.rc('text', usetex=True) # comment out this line if you don't have latex installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fits= []\n",
    "for i, w in enumerate(two_pcf_results):\n",
    "    w_fit= amplitudes[i]*deg_theta_cen**(-0.8)\n",
    "    w_fits.append(w_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit the power-law model to each catalog\n",
    "model_results = []\n",
    "for i, w in enumerate(two_pcf_results):\n",
    "    \n",
    "    # Extract data for fitting\n",
    "    cuts = (deg_theta_cen > 3e-3) & (deg_theta_cen < 1)\n",
    "    X = deg_theta_cen[cuts]\n",
    "    Y = w[cuts]\n",
    "    fractional_error = 1 / np.sqrt(dd_counts)\n",
    "    errorbars = fractional_error * (norma_dd / norma_rr)  #So the errorbar on the ratio DD/RR is: ( 1 / sqrt(number of  DD pairs) ) * DD/RR\n",
    "    \n",
    "    #w_fit= amps[i]*deg_theta_cen**(-0.8) #w(theta)    \n",
    "    \n",
    "    Y_err = errorbars[cuts]  \n",
    "    mask_rr = rr_counts[cuts]\n",
    "    \n",
    "\n",
    "    # Build the PyMC model\n",
    "    with pm.Model() as model:\n",
    "        rr = pm.ConstantData(\"rr\", mask_rr, dims=\"observation\")\n",
    "\n",
    "        # Define priors\n",
    "        power = pm.Normal(\"power\", mu=-0.8, sigma=10)\n",
    "        A = pm.Normal(\"A\", mu=2e-2, sigma=10)\n",
    "        #A = pm.Normal(\"A\", mu=amplitudes[i], sigma=10)\n",
    "\n",
    "        #Y_pred = A * (X** power)\n",
    "        \n",
    "        #!!!!! this is what i changed here!!!!\n",
    "        Y_pred = A * (X** (-0.8))\n",
    "\n",
    "        IC = pm.math.sum(Y_pred * rr / pm.math.sum(rr))\n",
    "\n",
    "        total_sigma = np.sqrt(Y_err**2)\n",
    "\n",
    "        # Define likelihood\n",
    "        likelihood = pm.Normal(\"Y\", mu=Y_pred - IC, sigma=total_sigma, observed=Y, dims=\"observation\")\n",
    "\n",
    "        # Inference\n",
    "        idata = pm.sample(3000)\n",
    "\n",
    "        # Extract posterior samples\n",
    "        power_post = np.array(idata.posterior['power']).flatten()\n",
    "        A_post = np.array(idata.posterior['A']).flatten()\n",
    "        \n",
    "\n",
    "        # Calculate median values\n",
    "        power_median = np.median(power_post)\n",
    "        A_median = np.median(A_post)\n",
    "\n",
    "        model_results.append((power_median, A_median))\n",
    "        \n",
    "\n",
    "# Print or analyze the model results for each catalog\n",
    "for i, (power_median, A_median) in enumerate(model_results):\n",
    "    print(f\"Subsample {i+1}:\")\n",
    "    print(f\"Power-law index: {power_median:.3f}\")\n",
    "    print(f\"Amplitude: {A_median:.3f}\")\n",
    "\n",
    "#lower_ci = np.quantile(power_post, 0.025)\n",
    "#upper_ci = np.quantile(power_post, 0.975)\n",
    "#print(f\"95% Confidence Interval: [{lower_ci:.3f}, {upper_ci:.3f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bcf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def integrand(z_prime):\n",
    "    return ((1 + z_prime)**3 + Omega0 - 1)**(-0.5)\n",
    "\n",
    "\n",
    "def x(z, H0, Omega0):\n",
    "    result, _ = integrate.quad(integrand, 0, z)\n",
    "    return result * (Omega0**(-0.5) * H0)\n",
    "\n",
    "def F(z, Omega0):\n",
    "    return 1\n",
    "\n",
    "def P(z, Omega0):\n",
    "    return np.sqrt(Omega0) * np.sqrt((1 + z) ** 3 +  Omega0**(- 1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2583e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Constants\n",
    "\n",
    "#gamma = 1.8\n",
    "H_gamma = 3.68\n",
    "c = 299792.458  # km/s\n",
    "Omega0 = 0.3\n",
    "Lambda = 1 - Omega0\n",
    "h0 = 0.70\n",
    "H0 = h0 * 100  # km/s/Mpc\n",
    "\n",
    "\n",
    "r0s= []\n",
    "\n",
    "\n",
    "    \n",
    "for i, (power_median, A_median) in enumerate(model_results):\n",
    "#for i, (catalog, two_pcf) in enumerate(zip(catalogs, two_pcf_results)):\n",
    "    print(f\"Subsample {i+1}:\")\n",
    "\n",
    "    delta_z = 0.05 # Width of redshift bin\n",
    "    #sigma = 0.1*(z_mean) + 1 # is the rms error on each redshift.\n",
    "    \n",
    "    gamma= (power_median * -1) + 1\n",
    "\n",
    "    numerator = c * A_median * delta_z\n",
    "    #numerator = c * amplitudes[i] * delta_z\n",
    "          \n",
    "\n",
    "    denominator = H0 * H_gamma * x(z_mean, H0, Omega0) ** (1 - gamma) * P(z_mean, Omega0) * F(z_mean, Omega0)\n",
    "    #print(z_mean_range[i])\n",
    "    r0 = (numerator / denominator) ** (1 / gamma)\n",
    "    \n",
    "    r0s.append(r0)\n",
    "\n",
    "\n",
    "print(\"r0 =\", r0s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_mean_range)\n",
    "#print(sigma)\n",
    "print(SM_mean_range[:2])\n",
    "\n",
    "#sm_mean_range_values = [8.25, 8.75, 9.25, 9.75, 10.25,10.75]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c260e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SM_mean_range[:2]\n",
    "z= z_mean_range\n",
    "print('len(m):',len(m))\n",
    "print('len(z):',len(z))\n",
    "\n",
    "zm=np.meshgrid(m,z)\n",
    "np.array(zm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zm=np.array(zm).reshape(2,-1)\n",
    "zm[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11244ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0s_reshaped = np.reshape(r0s, (len(m), len(z)))  # since r0s is a flattened array\n",
    "#print(r0s_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d445ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(m)):\n",
    "    plt.plot(z, r0s_reshaped[i], label=f\"SM = {m[i]}\",marker='o')\n",
    "\n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(r\"$r_0$ vs. Redshift (Different Stellar Mass Ranges)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"r0_vs_redshift_for_diff_SM.png\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r0s_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(m)):\n",
    "    sigma = [0.1 * z_mean + 1 for z_mean in z]  # is the rms error on each redshift\n",
    "    plt.errorbar(z, r0s_reshaped[i], yerr=sigma, label=f\"SM = {m[i]}\",marker='o',capsize=7,)\n",
    "\n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(r\"$r_0$ vs. Redshift (Different Stellar Mass Ranges)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"r0_vs_redshift_for_diff_SM_sigma.png\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a397171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dictionary to map stellar mass to color\n",
    "color_map = {}\n",
    "unique_masses = np.unique(SM_mean_range)  # Get unique stellar mass values\n",
    "\n",
    "# Assign a color to each unique mass\n",
    "cmap = plt.cm.viridis  # Choose a colormap (adjust as needed)\n",
    "norm = plt.Normalize(vmin=min(unique_masses), vmax=max(unique_masses))\n",
    "\n",
    "for i, mass in enumerate(unique_masses):\n",
    "    color_map[mass] = cmap(norm(mass))  # Map mass to color\n",
    "\n",
    "# Plotting loop\n",
    "plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
    "\n",
    "for i, (catalog, two_pcf, z_mean, r0, mass) in enumerate(zip(catalogs, two_pcf_results, z_mean_range, r0s, SM_mean_range)):\n",
    "    color = color_map[mass]  # Get color based on stellar mass\n",
    "    plt.scatter(z_mean, r0, label=f\"Subsample {i+1} (Mass: {mass})\", color=color)\n",
    "    print('z', z_mean_range[i])\n",
    "    print(\"SM_mean_range\",SM_mean_range[i])\n",
    "    print() \n",
    "    \n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(r\"$r_0$ vs. Redshift (Different Stellar Mass Ranges)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a0708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00876d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a627cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r0subsets= []\n",
    "\n",
    "\n",
    "for sm in sm_mean_range_values:\n",
    "    for i, (catalog, two_pcf) in enumerate(zip(catalogs, two_pcf_results)):\n",
    "        print(f\"Subsample {i+1}:\")\n",
    "        #print(amplitudes[i])\n",
    "        delta_z = 0.05 # Width of redshift bin\n",
    "        #sigma = 0.1*(z_mean_range[i]) + 1# is the rms error on each redshift.\n",
    "\n",
    "        #numerator = c * A_median * delta_z\n",
    "        numerator = c * amplitudes[i] * delta_z\n",
    "\n",
    "\n",
    "        denominator = H0 * H_gamma * x(z_mean, H0, Omega0) ** (1 - gamma) * P(z_mean, Omega0) * F(z_mean, Omega0)\n",
    "        r0_try = (numerator / denominator) ** (1 / gamma)\n",
    "\n",
    "        r0subsets.append(r0_try)\n",
    "        print(r0_try)\n",
    "\n",
    "\n",
    "print(\"r0 =\", r0subsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7356e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85571e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, subsamples in enumerate(subsamples):\n",
    "for i in range(len(catalogs)):\n",
    "\n",
    "    plt.scatter(z_mean, r0s[i], color='k') \n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(r\"$r_0$ vs. Redshift (Different Stellar Mass Ranges)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (catalog, two_pcf, z_mean, r0, mass) in enumerate(zip(catalogs, two_pcf_results, z_mean_range, r0s, SM_mean_range)):\n",
    "    plt.scatter(z_mean, r0, label=f\"Subsample {i+1} (Mass: {mass})\")\n",
    "    print(z_mean)\n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(r\"$r_0$ vs. Redshift (Different Stellar Mass Ranges)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42887b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r0 = [7.919801737440025, 9.310524633095541, 9.983241506039718, 7.472582758869569, 9.018550727903092, 4.692336550191943, 7.979077043419786, 7.887660010600186, 6.777461765443315, 3.4967127571738827, 2.1718931951889355, 6.88764906933823, 8.359006930215227, 7.8956305871071795, 4.622186299154375, 6.117504017718696, 5.279954658750212, 5.374296907330983]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fdc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SM_mean_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3907d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dictionary to map stellar mass to color\n",
    "color_map = {}\n",
    "unique_masses = np.unique(SM_mean_range)  # Get unique stellar mass values\n",
    "\n",
    "# Assign a color to each unique mass\n",
    "cmap = plt.cm.viridis  # Choose a colormap (adjust as needed)\n",
    "norm = plt.Normalize(vmin=min(unique_masses), vmax=max(unique_masses))\n",
    "\n",
    "for i, mass in enumerate(unique_masses):\n",
    "    color_map[mass] = cmap(norm(mass))  # Map mass to color\n",
    "\n",
    "# Plotting loop\n",
    "plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
    "\n",
    "for i, (catalog, two_pcf, z_mean, r0, mass) in enumerate(zip(catalogs, two_pcf_results, z_mean_range, r0s, SM_mean_range)):\n",
    "    color = color_map[mass]  # Get color based on stellar mass\n",
    "    plt.scatter(z_mean, r0, label=f\"Subsample {i+1} (Mass: {mass})\", color=color)\n",
    "    print('z', z_mean_range[i])\n",
    "    print(\"SM_mean_range\",SM_mean_range[i])\n",
    "    print() \n",
    "    \n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(r\"$r_0$ vs. Redshift (Different Stellar Mass Ranges)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1333ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(catalogs)):\n",
    "        print(r0s[i])\n",
    "print(len(r0s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z_mean_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c83875",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_z = np.unique(z_mean_range)  # Get unique stellar mass values\n",
    "\n",
    "print(unique_z)\n",
    "# Assign a color to each unique mass\n",
    "cmap = plt.cm.magma  # Choose a colormap (adjust as needed)\n",
    "#norm_z = plt.Normalize(vmin=min(unique_z), vmax=max(unique_z))\n",
    "\n",
    "#print(norm_z)\n",
    "\n",
    "for i, redshift in enumerate(unique_z):\n",
    "    color_map[redshift] = cmap(redshift)  # Map mass to color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm_mean_range_values = [8.25, 8.75, 9.25, 9.75, 10.25]\n",
    "\n",
    "\n",
    "for z in range(len(z_mean_range)):\n",
    "\n",
    "    for i in range(len(catalogs)):\n",
    "        \n",
    "        plt.scatter(z_mean_range[z], r0s[i])\n",
    "        #plt.scatter(z_mean_range[z], r0subsets[i])\n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(f\"r0 vs. Redshift (z = {z_mean_range[z]}) - Different Stellar Mass Ranges\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print the z and SM_mean_range values for reference (optional)\n",
    "for z in range(len(z_mean_range)):\n",
    "    print(f\"Redshift (z): {z_mean_range[z]}\")\n",
    "    \n",
    "    for i, mass in enumerate(sm_mean_range_values):\n",
    "        \n",
    "        print(f\"Stellar Mass Range: {mass}\")\n",
    "        print( \"r0:\",  r0subsets[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91644b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_mean_range_values = [8.25, 8.75, 9.25, 9.75, 10.25]\n",
    "\n",
    "\n",
    "for z in z_mean_range:\n",
    "    for SM in sm_mean_range_values:\n",
    "        # Do something with z and sm_mean_range\n",
    "        print(f\"z: {z}, SM_mean_range: {SM}\")\n",
    "     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_subsample = t['z'][subsample]\n",
    "SM_subsample = t['SM'][subsample]\n",
    "\n",
    "print(z_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9b740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Constants\n",
    "gamma = 1.8\n",
    "H_gamma = 3.68\n",
    "c = 299792.458  # km/s\n",
    "Omega0 = 0.3\n",
    "Lambda = 1 - Omega0\n",
    "h0 = 0.70\n",
    "H0 = h0 * 100  # km/s/Mpc\n",
    "\n",
    "\n",
    "    \n",
    "r0_dict = {}\n",
    "\n",
    "for i, (catalog, two_pcf) in enumerate(zip(catalogs, two_pcf_results)):\n",
    "    print(f\"Subsample {i+1}:\")\n",
    "    delta_z = 0.05 # Width of redshift bin\n",
    "    #sigma = 0.1*(z_mean_range[i]) + 1# is the rms error on each redshift.\n",
    "\n",
    "    #numerator = c * A_median * delta_z\n",
    "    numerator = c * amplitudes[i] * delta_z\n",
    "          \n",
    "\n",
    "    denominator = H0 * H_gamma * x(z_mean, H0, Omega0) ** (1 - gamma) * P(z_mean, Omega0) * F(z_mean, Omega0)\n",
    "    r0 = (numerator / denominator) ** (1 / gamma)\n",
    "    \n",
    "\n",
    "    # Assuming you have stellar mass and redshift information for each catalog\n",
    "    stellar_mass = SM_subsample[i]\n",
    "    redshift = z_subsample[i]\n",
    "\n",
    "    r0_dict[(stellar_mass, redshift)] = r0\n",
    "    print(f\"Stellar Mass: {stellar_mass}, Redshift: {redshift}, r0: {r0}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_by_mass = {}\n",
    "\n",
    "for (stellar_mass, redshift), r0 in r0_dict.items():\n",
    "    if stellar_mass not in r0_by_mass:\n",
    "        r0_by_mass[stellar_mass] = []\n",
    "    r0_by_mass[stellar_mass].append((redshift, r0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for stellar_mass, data in r0_by_mass.items():\n",
    "    redshifts, r0s = zip(*data)\n",
    "    plt.scatter(redshifts, r0s)\n",
    "\n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(\"r0 vs. Redshift for Different Stellar Mass Ranges\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8dac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_subsample = t['z'][subsamples]\n",
    "SM_subsample = t['SM'][subsample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  # Import colormap library\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a colormap for different stellar mass ranges\n",
    "cmap = cm.get_cmap('tab10')  # Choose a colormap (other options available)\n",
    "\n",
    "# Loop through data with color assignment\n",
    "for i, (stellar_mass, data) in enumerate(r0_by_mass.items()):\n",
    "    redshifts, r0s = zip(*data)\n",
    "    plt.scatter(redshifts, r0s, label=f\"{stellar_mass} Msun\", c=cmap(i))  # Use colormap index\n",
    "\n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(r\"$r_0 (h^{-1} Mpc)$\")\n",
    "plt.title(\"r0 vs. Redshift for Different Stellar Mass Ranges\")\n",
    "plt.legend(title=\"Stellar Mass Range\")  # Add legend title\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c16ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
